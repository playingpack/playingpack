{
  // Sample Config file
  // Upstream API URL (default: https://api.openai.com)
  // Examples:
  //   - Ollama: http://localhost:11434/v1
  //   - Azure: https://YOUR_RESOURCE.openai.azure.com
  //   - vLLM: http://localhost:8000/v1
  "upstream": "https://api.openai.com",

  // Directory for tape storage
  "tapesDir": "dir/to/tapes",

  // Directory for log files
  "logsDir": "dir/to/logs",

  // Recording mode:
  //   - auto: Record on cache miss, replay on hit (default)
  //   - off: Passthrough only, no recording or replay
  //   - replay-only: Replay only, fail if no tape exists
  "record": "auto",

  // Run without UI (headless mode for CI/CD)
  "headless": false,

  // Server port
  "port": 8888,

  // Server host
  "host": "0.0.0.0",

  // Enable pause mode to intercept requests (default: false)
  "pauseEnabled": false,

  // When pause mode is enabled:
  //   - true: Only pause requests that contain tool calls (default)
  //   - false: Pause all requests
  "pauseOnToolCalls": true
}
